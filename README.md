### Table of content

1. What is feature engineering ?
2. What happens when feature engineering is done ?
3. Types of features/variables.
    - 3.1 [Numerical feature](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.1_types_of_variable_or_features/0.1.1_numerical_variable.py)
    - 3.2 [Categorical feature](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.1_types_of_variable_or_features/0.1.2_categorical_variables.py)
    - 3.3 [Date time feature](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.1_types_of_variable_or_features/0.1.3_date_time_variables.py)
    - 3.4 [Mixed feature](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.1_types_of_variable_or_features/0.1.4_mixed_variables.py)
4. Feature Characteristics
    - 4.1 [Missing values](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.1_missing_values.py)
    - 4.2 [Cardinality](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.2_cardinality.py)
    - 4.3 [Rare Labels](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.3_rare_labels.py)
    - 4.4 [Linear model assumptions](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.4_linear_models_assumptions.py)
    - 4.5 [Outliers](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.5_outliers.py)
    - 4.6 [Variable magnitude](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.2_variable_characteristics/0.2.6_variable_magnitude.py)
5. Missing value imputation
    - 5.1 [Complete case analysis](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.1_complete_case_analysis.py)
    - 5.2 [Drop missing value observations](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.3_dropna_data_distribution_check.py)
    - 5.3 [Mean & median imputation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.4_mean_median_imputation.py)
    - 5.4 [Arbitary value imputation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.5_arbitary_value_imputation.py)
    - 5.5 [End of distribution imputation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.6_end_of_distribution_imputation.py)
    - 5.6 [Frequent or mode category imputation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.7_frequent_or_mode_category_imputation.py)
    - 5.7 [Random sample imputation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.9_random_sample_imputation.py)
    - 5.8 [Missing indicator](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.3_missing%20value%20imputation/0.10_missing_indicator.py)
6. Categorical encoding
    - 6.1 [One hot encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.1_one_hot_encoding.py)
    - 6.2 [One hot encoding of frequent categories](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.2_one_hot_encoding_of_frequent_categories.py)
    - 6.3 [Integer encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.3_integer_encoding.py)
    - 6.4 [Count or frequency encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.4_count_or_frequency_encoding.py)
    - 6.5 [Target ordered mean integer encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.5_target_ordered_mean_integer_encoding.py)
    - 6.6 [Target mean encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.6_target_mean_encoding.py)
    - 6.7 [Target probability ratio encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.7_target_probability_ratio_encoding.py)
    - 6.8 [Target weight of evidence encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.8_target_weight_of_evidence_encoding.py)
    - 6.9 [Engineering rare categories](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.4_categorical%20encoding/0.10_engineering_rare_categories.py)
7. Feature/Variable Transformation
    - 7.1 [Gaussian transformation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.5_variable_transformation/0.5.1_gaussian_transformation.py)
8. Discretisation
    - 8.1 [Equal width discretisation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.1_equal_width_discretisation.py)
    - 8.2 [Equal frequency discretisation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.2_equal_frequency_discretisation.py)
    - 8.2 [K-means discretisation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.3_kmeans_discretisation.py)
    - 8.3 [Discretisation plus encoding](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.4_discretisation_plus_encoding.py)
    - 8.4 [Discretisation using decision tree ](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.5_discretisation_using_decisionTree.py)
    - 8.5 [Discretisation based on domain knowledge](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.6_discretisation/0.6.6_domain_knowledge_discretisation.py)
9. Outlier engineering
    - 9.1 [Trim outlier](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.7_outlier_engineering/0.7.1_outlier_trimming.py)
    - 9.2 [Capping & IQR proximity rule](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.7_outlier_engineering/0.7.2_capping_IQR_proximity_rule.py)
    - 9.3 [Capping gausian approximation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.7_outlier_engineering/0.7.3_capping_gaussian_approximation.py)
    - 9.4 [Capping quantiles](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.7_outlier_engineering/0.7.4_capping_quantiles.py)
    - 9.5 [Capping arbitrary](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.7_outlier_engineering/0.7.5_capping_arbitrary.py)
10. Feature scaling
    - 10.1 [Standardisation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.1_standardisation.py)
    - 10.2 [Mean normalisation](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.2_mean_normalisation.py)
    - 10.3 [MinMaxScaling](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.3_minMaxScaling.py)
    - 10.4 [Maximum absolute scaling](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.4_maximum_absolute_scaling.py)
    - 10.5 [Robust scaling](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.5_robust_scaling.py)
    - 10.6 [Scaling to unit length](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.8_feature_scaling/0.8.6_scaling_to_unit_length.py)
11. Feature engineering mixed variable
    - 11.1 [Engineering mixed variable](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.9_mixed_variables/0.9.1_engineering_mixed_variables.py)
12. Feature engineering date and time
    - 12.1 [Engineering date](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.10_engineering_date_time/0.10.1_engineering_date.py)
    - 12.1 [Engineering time](https://github.com/Akshaykumarcp/ML-Feature-Engineering/blob/main/0.10_engineering_date_time/0.10.2_engineering_time.py)
13. References & credits
14. Connect with me

---

> **Note** :scroll:  
> - Feature and Variable are used interchangeably. Feature and Variable convey same meaning.
> - Please find what, why & how part of specific topic inside the file "filename.py". 

### 1. What is feature engineering :man_technologist: :question:

- One reason for success of a ML project is coming up with a good set of features to train on. 
- The process of obtaining a good set of features is called as feature engineering.

### 2. What happens when feature engineering is done :question:

- Improve performance of machine learning model
- Feature engineering represents data 

### 13. References & Credits :handshake:
- [Feature Engine](https://feature-engine.readthedocs.io/en/1.2.x/)
- [Feature Engineering for Machine Learning](https://www.udemy.com/feature-engineering-for-machine-learning)

### 14. Connect with me :smiley:

[<img align="left" alt="" width="22px" src="https://simpleicons.org/icons/linkedin.svg" />](https://www.linkedin.com/in/akshay-kumar-c-p/)
[<img align="left" alt="" width="22px" src="https://simpleicons.org/icons/youtube.svg" />](https://www.youtube.com/channel/UC3l8RTE3zBRzUrHbSXpx-qA)
[<img align="left" alt="" width="22px" src="https://simpleicons.org/icons/github.svg" />](https://github.com/Akshaykumarcp)
[<img align="left" alt="" width="22px" src="https://simpleicons.org/icons/medium.svg" />](https://medium.com/@akshai.148)


